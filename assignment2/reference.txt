https://github.com/ChilunC/Assignment2/blob/master/trainCifarStarterCode.py
https://github.com/aimeecong/CNN/blob/e89d659f6ef69af20668d909b7650878c8affe6a/trainCifarStarterCode.py
below with report good Q2 ans
https://github.com/Keyspan/comp576/tree/51ff661899b5d71cd74bae0e497228515575fc7b/hw2
below with report
https://github.com/bl166/LearningDeepLearning/blob/662ed854729243aa43ba80a1699e0fa9c6f4d0aa/ass2/trainCifarStarterCode.py
new

https://github.com/luffycodes/ELEC576/blob/828d856aed99415b09a7bcdcdad309466cf720e4/Assignment2/trainCifarStarterCode.py
below with report 
https://github.com/abhmul/COMP-576/blob/6481e5510f17c160f6369ba926f6835e16abae6a/Assignment2/trainCifarStarterCode.py
https://github.com/guopeisheng/Deep-Learning-Course/blob/f5ccc2db2e16ba2e064a8a01a496fe7e0c2ee43e/Deep%20L%20HW02/trainCifarStarterCode.py
https://github.com/chetanmaddula/Deep-Learning/blob/449d53261e132b79d1ef5db94fb6986aef1a4a6f/dcn_mnist.py
https://github.com/afung-git/COMP576/blob/3c59bb9e2ba4d6a333f078ed5e62572db6d65a25/Assignment2/trainCifarStarterCode.py

to go
https://github.com/bl166/LearningDeepLearning/tree/a84436b9c7115dab9fb9a3b8312eb9f7c7c820b8/ass2

https://github.com/dlej/elec576/blob/master/assignment2/Assignment%202.ipynb

https://github.com/ZengChen94/Introduction-to-Deep-Learning/tree/203c3c25c7148e3791c40c3939451341e18cb169/Assignment%202

step: 100 with lr: 0.0001, train accuracy:0.36399999260902405, loss:1.8709758520126343
step: 200 with lr: 0.0001, train accuracy:0.4339999854564667, loss:1.6896460056304932
step: 300 with lr: 0.0001, train accuracy:0.4740000069141388, loss:1.5688660144805908
step: 400 with lr: 0.0001, train accuracy:0.5130000114440918, loss:1.4419045448303223
step: 500 with lr: 0.0001, train accuracy:0.5649999976158142, loss:1.3443702459335327
step: 600 with lr: 0.0001, train accuracy:0.5820000171661377, loss:1.2703765630722046
step: 700 with lr: 0.0001, train accuracy:0.6140000224113464, loss:1.2034474611282349
step: 800 with lr: 0.0001, train accuracy:0.6660000085830688, loss:1.090125560760498
step: 900 with lr: 0.0001, train accuracy:0.7110000252723694, loss:0.9825971722602844
step: 1000 with lr: 0.0001, train accuracy:0.7310000061988831, loss:0.8937634229660034
step: 1100 with lr: 0.0001, train accuracy:0.7379999756813049, loss:0.8839544057846069
step: 1200 with lr: 0.0001, train accuracy:0.777999997138977, loss:0.7789127230644226
step: 1300 with lr: 0.0001, train accuracy:0.7850000262260437, loss:0.7431259751319885
step: 1400 with lr: 0.0001, train accuracy:0.8450000286102295, loss:0.6749355792999268
step: 1500 with lr: 0.0001, train accuracy:0.8220000267028809, loss:0.6695387959480286
step: 1600 with lr: 0.0001, train accuracy:0.8500000238418579, loss:0.589007556438446
step: 1700 with lr: 0.0001, train accuracy:0.8610000014305115, loss:0.5664371252059937
step: 1800 with lr: 0.0001, train accuracy:0.878000020980835, loss:0.5017315149307251
step: 1900 with lr: 0.0001, train accuracy:0.8889999985694885, loss:0.47139406204223633
test accuracy 0.524
step: 0 with lr: 0.001, train accuracy:0.09000000357627869, loss:7.135001182556152
step: 100 with lr: 0.001, train accuracy:0.5260000228881836, loss:1.4150735139846802
step: 200 with lr: 0.001, train accuracy:0.6299999952316284, loss:1.059677243232727
step: 300 with lr: 0.001, train accuracy:0.7799999713897705, loss:0.7635201811790466
step: 400 with lr: 0.001, train accuracy:0.8679999709129333, loss:0.5063105225563049
step: 500 with lr: 0.001, train accuracy:0.9309999942779541, loss:0.2985170781612396
step: 600 with lr: 0.001, train accuracy:0.9599999785423279, loss:0.19327899813652039
step: 700 with lr: 0.001, train accuracy:0.9829999804496765, loss:0.10155193507671356
step: 800 with lr: 0.001, train accuracy:0.9929999709129333, loss:0.05773967504501343
step: 900 with lr: 0.001, train accuracy:0.9940000176429749, loss:0.04021626338362694
step: 1000 with lr: 0.001, train accuracy:0.9990000128746033, loss:0.021407898515462875
step: 1100 with lr: 0.001, train accuracy:0.9990000128746033, loss:0.01622181385755539
step: 1200 with lr: 0.001, train accuracy:0.9990000128746033, loss:0.010016142390668392
step: 1300 with lr: 0.001, train accuracy:1.0, loss:0.006367949303239584
step: 1400 with lr: 0.001, train accuracy:0.09799999743700027, loss:nan
step: 1500 with lr: 0.001, train accuracy:0.09799999743700027, loss:nan
step: 1600 with lr: 0.001, train accuracy:0.09399999678134918, loss:nan
step: 1700 with lr: 0.001, train accuracy:0.09000000357627869, loss:nan
step: 1800 with lr: 0.001, train accuracy:0.0860000029206276, loss:nan
step: 1900 with lr: 0.001, train accuracy:0.0989999994635582, loss:nan
test accuracy 0.1
step: 0 with lr: 0.0005, train accuracy:0.10300000011920929, loss:8.279521942138672
step: 100 with lr: 0.0005, train accuracy:0.4390000104904175, loss:1.599713921546936
step: 200 with lr: 0.0005, train accuracy:0.5699999928474426, loss:1.268099308013916
step: 300 with lr: 0.0005, train accuracy:0.7049999833106995, loss:0.9529643654823303
step: 400 with lr: 0.0005, train accuracy:0.7749999761581421, loss:0.7762094736099243
step: 500 with lr: 0.0005, train accuracy:0.8640000224113464, loss:0.5269903540611267
step: 600 with lr: 0.0005, train accuracy:0.9350000023841858, loss:0.3565264940261841
step: 700 with lr: 0.0005, train accuracy:0.9520000219345093, loss:0.2698851227760315
step: 800 with lr: 0.0005, train accuracy:0.9670000076293945, loss:0.19356994330883026
step: 900 with lr: 0.0005, train accuracy:0.9760000109672546, loss:0.13495993614196777
step: 1000 with lr: 0.0005, train accuracy:0.9860000014305115, loss:0.09930000454187393
step: 1100 with lr: 0.0005, train accuracy:0.9940000176429749, loss:0.06302492320537567
step: 1200 with lr: 0.0005, train accuracy:0.9950000047683716, loss:0.050825513899326324
step: 1300 with lr: 0.0005, train accuracy:0.9950000047683716, loss:0.039616018533706665
step: 1400 with lr: 0.0005, train accuracy:1.0, loss:0.022917598485946655
step: 1500 with lr: 0.0005, train accuracy:1.0, loss:0.015102588571608067
step: 1600 with lr: 0.0005, train accuracy:1.0, loss:0.010335289873182774
step: 1700 with lr: 0.0005, train accuracy:1.0, loss:0.0085197314620018
step: 1800 with lr: 0.0005, train accuracy:1.0, loss:0.007541197817772627
step: 1900 with lr: 0.0005, train accuracy:1.0, loss:0.0060438308864831924
test accuracy 0.557
step: 0 with lr: 0.0002, train accuracy:0.10700000077486038, loss:5.955345153808594
step: 100 with lr: 0.0002, train accuracy:0.38199999928474426, loss:1.780961036682129
step: 200 with lr: 0.0002, train accuracy:0.48500001430511475, loss:1.5126492977142334
step: 300 with lr: 0.0002, train accuracy:0.6019999980926514, loss:1.2916758060455322
step: 400 with lr: 0.0002, train accuracy:0.6140000224113464, loss:1.1653828620910645
step: 500 with lr: 0.0002, train accuracy:0.6650000214576721, loss:1.056459903717041
step: 600 with lr: 0.0002, train accuracy:0.7329999804496765, loss:0.9452137351036072
step: 700 with lr: 0.0002, train accuracy:0.7799999713897705, loss:0.7863494753837585
step: 800 with lr: 0.0002, train accuracy:0.7879999876022339, loss:0.7298423647880554
step: 900 with lr: 0.0002, train accuracy:0.8510000109672546, loss:0.6033321619033813
step: 1000 with lr: 0.0002, train accuracy:0.8899999856948853, loss:0.4978642463684082
step: 1100 with lr: 0.0002, train accuracy:0.9100000262260437, loss:0.4170125424861908
step: 1200 with lr: 0.0002, train accuracy:0.9290000200271606, loss:0.35202378034591675
step: 1300 with lr: 0.0002, train accuracy:0.9559999704360962, loss:0.29648175835609436
step: 1400 with lr: 0.0002, train accuracy:0.9570000171661377, loss:0.2715003788471222
step: 1500 with lr: 0.0002, train accuracy:0.9710000157356262, loss:0.22471261024475098
step: 1600 with lr: 0.0002, train accuracy:0.9739999771118164, loss:0.19227315485477448
step: 1700 with lr: 0.0002, train accuracy:0.9779999852180481, loss:0.15744498372077942
step: 1800 with lr: 0.0002, train accuracy:0.9789999723434448, loss:0.12651628255844116
step: 1900 with lr: 0.0002, train accuracy:0.9929999709129333, loss:0.09879185259342194
test accuracy 0.558

GradientDescendent
step: 10 with lr: 0.0001, train accuracy:0.10000000149011612, loss:5.055963516235352
step: 20 with lr: 0.0001, train accuracy:0.1469999998807907, loss:4.014303207397461
step: 30 with lr: 0.0001, train accuracy:0.11699999868869781, loss:3.68550443649292
step: 40 with lr: 0.0001, train accuracy:0.11999999731779099, loss:3.303524971008301
step: 50 with lr: 0.0001, train accuracy:0.12700000405311584, loss:2.987684488296509
step: 60 with lr: 0.0001, train accuracy:0.10300000011920929, loss:2.899961471557617
step: 70 with lr: 0.0001, train accuracy:0.0989999994635582, loss:2.8206088542938232
step: 80 with lr: 0.0001, train accuracy:0.0989999994635582, loss:2.7389960289001465
step: 90 with lr: 0.0001, train accuracy:0.11400000005960464, loss:2.696408748626709
step: 100 with lr: 0.0001, train accuracy:0.09300000220537186, loss:2.6743826866149902
step: 110 with lr: 0.0001, train accuracy:0.10999999940395355, loss:2.59224796295166
step: 120 with lr: 0.0001, train accuracy:0.10499999672174454, loss:2.580019235610962
step: 130 with lr: 0.0001, train accuracy:0.11299999803304672, loss:2.5095009803771973
step: 140 with lr: 0.0001, train accuracy:0.10599999874830246, loss:2.5577402114868164
step: 150 with lr: 0.0001, train accuracy:0.11500000208616257, loss:2.4760468006134033
step: 160 with lr: 0.0001, train accuracy:0.10899999737739563, loss:2.4918344020843506
step: 170 with lr: 0.0001, train accuracy:0.12700000405311584, loss:2.463592529296875
step: 180 with lr: 0.0001, train accuracy:0.10100000351667404, loss:2.4664812088012695
step: 190 with lr: 0.0001, train accuracy:0.11299999803304672, loss:2.4707143306732178
test accuracy 0.115
step: 0 with lr: 0.001, train accuracy:0.13199999928474426, loss:6.477588176727295
step: 10 with lr: 0.001, train accuracy:0.11999999731779099, loss:2.649353265762329
step: 20 with lr: 0.001, train accuracy:0.13099999725818634, loss:2.4704325199127197
step: 30 with lr: 0.001, train accuracy:0.12800000607967377, loss:2.414318799972534
step: 40 with lr: 0.001, train accuracy:0.12999999523162842, loss:2.394406318664551
step: 50 with lr: 0.001, train accuracy:0.14000000059604645, loss:2.364035129547119
step: 60 with lr: 0.001, train accuracy:0.12800000607967377, loss:2.361938953399658
step: 70 with lr: 0.001, train accuracy:0.1340000033378601, loss:2.3527724742889404
step: 80 with lr: 0.001, train accuracy:0.1340000033378601, loss:2.3619515895843506
step: 90 with lr: 0.001, train accuracy:0.14100000262260437, loss:2.3404200077056885
step: 100 with lr: 0.001, train accuracy:0.14100000262260437, loss:2.3339295387268066
step: 110 with lr: 0.001, train accuracy:0.15800000727176666, loss:2.3152289390563965
step: 120 with lr: 0.001, train accuracy:0.13600000739097595, loss:2.316159248352051
step: 130 with lr: 0.001, train accuracy:0.15800000727176666, loss:2.2792069911956787
step: 140 with lr: 0.001, train accuracy:0.1720000058412552, loss:2.2730653285980225
step: 150 with lr: 0.001, train accuracy:0.17399999499320984, loss:2.2652087211608887
step: 160 with lr: 0.001, train accuracy:0.16200000047683716, loss:2.2710156440734863
step: 170 with lr: 0.001, train accuracy:0.1589999943971634, loss:2.265401840209961
step: 180 with lr: 0.001, train accuracy:0.15000000596046448, loss:2.289185047149658
step: 190 with lr: 0.001, train accuracy:0.17299999296665192, loss:2.2483530044555664
test accuracy 0.168
step: 0 with lr: 0.0005, train accuracy:0.08799999952316284, loss:7.671911239624023
step: 10 with lr: 0.0005, train accuracy:0.10300000011920929, loss:3.2138452529907227
step: 20 with lr: 0.0005, train accuracy:0.10999999940395355, loss:2.662616729736328
step: 30 with lr: 0.0005, train accuracy:0.12800000607967377, loss:2.545738935470581
step: 40 with lr: 0.0005, train accuracy:0.10400000214576721, loss:2.5147087574005127
step: 50 with lr: 0.0005, train accuracy:0.10700000077486038, loss:2.459068775177002
step: 60 with lr: 0.0005, train accuracy:0.10899999737739563, loss:2.4526796340942383
step: 70 with lr: 0.0005, train accuracy:0.10100000351667404, loss:2.4380147457122803
step: 80 with lr: 0.0005, train accuracy:0.11599999666213989, loss:2.4440200328826904
step: 90 with lr: 0.0005, train accuracy:0.09700000286102295, loss:2.446580648422241
step: 100 with lr: 0.0005, train accuracy:0.10700000077486038, loss:2.382805585861206
step: 110 with lr: 0.0005, train accuracy:0.11800000071525574, loss:2.4081475734710693
step: 120 with lr: 0.0005, train accuracy:0.11100000143051147, loss:2.369323253631592
step: 130 with lr: 0.0005, train accuracy:0.12800000607967377, loss:2.3588364124298096
step: 140 with lr: 0.0005, train accuracy:0.13199999928474426, loss:2.365205764770508
step: 150 with lr: 0.0005, train accuracy:0.1340000033378601, loss:2.341778516769409
step: 160 with lr: 0.0005, train accuracy:0.12700000405311584, loss:2.36344838142395
step: 170 with lr: 0.0005, train accuracy:0.1340000033378601, loss:2.363676071166992
step: 180 with lr: 0.0005, train accuracy:0.11299999803304672, loss:2.349369525909424
step: 190 with lr: 0.0005, train accuracy:0.11100000143051147, loss:2.369417428970337
test accuracy 0.122
step: 0 with lr: 0.0002, train accuracy:0.1120000034570694, loss:4.51663875579834
step: 10 with lr: 0.0002, train accuracy:0.10199999809265137, loss:3.6504595279693604
step: 20 with lr: 0.0002, train accuracy:0.10499999672174454, loss:3.099184989929199
step: 30 with lr: 0.0002, train accuracy:0.10000000149011612, loss:2.9811530113220215
step: 40 with lr: 0.0002, train accuracy:0.10599999874830246, loss:2.8619673252105713
step: 50 with lr: 0.0002, train accuracy:0.08299999684095383, loss:2.7813098430633545
step: 60 with lr: 0.0002, train accuracy:0.10199999809265137, loss:2.741333484649658
step: 70 with lr: 0.0002, train accuracy:0.10700000077486038, loss:2.6574227809906006
step: 80 with lr: 0.0002, train accuracy:0.11400000005960464, loss:2.681375503540039
step: 90 with lr: 0.0002, train accuracy:0.11400000005960464, loss:2.608564615249634
step: 100 with lr: 0.0002, train accuracy:0.09799999743700027, loss:2.636455535888672
step: 110 with lr: 0.0002, train accuracy:0.11900000274181366, loss:2.5765786170959473
step: 120 with lr: 0.0002, train accuracy:0.11100000143051147, loss:2.5445504188537598
step: 130 with lr: 0.0002, train accuracy:0.11100000143051147, loss:2.543668508529663
step: 140 with lr: 0.0002, train accuracy:0.12800000607967377, loss:2.5162007808685303
step: 150 with lr: 0.0002, train accuracy:0.11299999803304672, loss:2.5070247650146484
step: 160 with lr: 0.0002, train accuracy:0.12700000405311584, loss:2.4975714683532715
step: 170 with lr: 0.0002, train accuracy:0.1340000033378601, loss:2.505951166152954
step: 180 with lr: 0.0002, train accuracy:0.10999999940395355, loss:2.482746124267578
step: 190 with lr: 0.0002, train accuracy:0.11500000208616257, loss:2.4505724906921387
test accuracy 0.116

FirstLayer activation stat: Min: -0.0,Max :1.7143521308898926,Mean:0.1757616549730301,std:0.21935726702213287,var:0.048117607831954956
SecondLayer activation stat: Min: -0.0,Max :4.481756687164307,Mean:0.030255336314439774,std:0.14025922119617462,var:0.01967264898121357

Test Accuracy: 128: 0.9121000170707703
Test Accuracy: 64: 0.8215000033378601
Test Accuracy: 256: 0.10130000114440918
Test Accuracy: RNN:0.8866000175476074, LSTM:0.7021999955177307,GRU :0.7318999767303467